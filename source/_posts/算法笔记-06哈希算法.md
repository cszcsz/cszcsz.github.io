---
title: 算法笔记-06哈希算法
date: 2019-11-20 19:05:15
categories: 数据结构与算法学习笔记
tags: [哈希算法]
keyword: 哈希算法
---

### 哈希算法

哈希算法定义：将任意长度的二进制值串映射为固定长度的二进制值串。

哈希算法所要满足的几点要求：

- 单向性（从哈希值不能反推出原始数据）
- 敏感性（对输入数据非常敏感，哪怕只修改了1个bit，最后得到的哈希值也大不相同）
- 平衡性（散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率很小）
- 高效性（哈希算法的执行效率要尽可能高，针对较长的文本也能够快速地计算出哈希值）

但是哈希算法无法做到零冲突！其背后原因其实是**鸽巢原理**：比如说MD5算法产生的哈希值是128位的二进制串，最多能表示2<sup>128</sup>的个数据。而我们要哈希的数据可是无穷的，如果我们对2<sup>128</sup>+1个数据求哈希值则必然会有两个数据的哈希值是相同的。

<br>

### 哈希算法的应用

#### 安全加密

最常用于加密的哈希算法是**MD5**（MD5 Message-Digest Algorithm,MD5 消息摘要算法）和**SHA**（Secure Hash Algorithm，安全散列算法） 

最简单的应用就是把用户的密码经过哈希以密文的形式存储在数据库中。由于哈希算法的不可逆性，黑客就算盗取了数据库的密码密文，也无法反推出原始密码。若想破解哈希算法如MD5，它有2<sup>128</sup>个不同的哈希值，这样想通过穷举的方法找到跟这个MD5值相同的另一个数据所耗费的时间是一个天文数字。所以，即便存在哈希冲突，但在有限时间和资源的情况下，哈希算法还是很难破解的。

另外，为了防止黑客通过彩虹表匹配（彩虹表中存放着某一哈希算法下常用密码对应的哈希值）获取用户真实密码。我们可以通过**+salt（加盐）**的做法来保证用户密码的安全，若用户设定的密码是“123456”，加盐之后是"12x3y456z"，这样再经过哈希得到是完全不一样的hash值。此外还可以采用随机加盐的做法，这样黑客拿到密文之后破解的难度就更高。

<br>

#### 唯一标识

哈希值又可以作为**“数字签名”**，来唯一标识对象。

举个栗子，我们想要在海量的图库中搜索图片是否存在，可以为每个图片取一个唯一标识（信息摘要），比如可以从一张图片的二进制码串的开头、中间、结尾各取100个字节合在一块再经过哈希算法得到一个hash值，用这个值作为图片的唯一标识。以后就可以通过标识来查找图片是否在图库中了。

<br>

#### 数据校验

BT 下载的原理是基于 P2P 协议的。我们从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成 100 块，每块大约 20MB）。等所有的文件块都下载完成之后，再组装成一个完整的电影文件就行了。

但是下载的文件块可能不完整或出现了bit错误，这时我们就要进行文件块的校验。我们可以先对100个文件块取哈希值并保存到种子文件中，再对下载好的文件块求哈希值并逐一和种子文件保存的哈希值对比。由于哈希算法的敏感性，就算出现一个bit错误产生的哈希值也大不相同。如果比较发现不同，则需要从其它服务器重新下载错误的文件块。

<br>

#### 散列函数

相对哈希算法的其他应用，散列函数对于散列算法冲突的要求要低很多。即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。 

散列函数对于散列算法计算得到的值，并不关心它是否能被反向解密。散列函数中用到的散列算法，更加关注散列后的值是否能**平均分布**。

另外，为了保证散列表的性能，散列函数用的散列算法一般**比较简单**，不会进行复杂的计算。

<br>

#### 负载均衡

如何才能实现一个会话粘滞（session sticky）的负载均衡算法呢 ?(即同一个客户端的一个会话中的所有请求都路由到同一个服务器上)。简单的做法是维护一张映射关系表，表中存着客户端ip地址与服务器id的映射关系，客户端的每次请求都要查表找到相应的服务器。但这种做法**映射表会很大，浪费内存空间，维护起来成本很大**。

我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。 

<br>

#### 数据分片

如何在1TB的日志文件中统计用户搜索关键词出现的次数呢？这么大的日志信息没办法放到一个机器的内存中，如果用一台机器来处理这么大的数据，处理时间也会非常长。

我们可以**对数据进行分片，然后采用分布式处理的办法**（多机处理）来提高处理速度。

我们遍历日志文件，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，**用这个哈希值跟n取模得到应该被分配到的机器编号**。这样，哈希值相同的关键词被分配到了同一台机器上，每台机器会分别统计关键词出现的次数，最后合并起来就是最终的结果。这里的处理过程也是MapReduce的基本设计思想。

**实际上，针对这种海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU 等资源的限制。** 

<br>

#### 分布式存储

我们为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。

我们有海量的数据需要缓存，所以一个缓存机器肯定是不够的。于是，我们就需要将数据分布在多台机器上。该如何决定将哪个数据放到哪个机器上呢？我们可以借用前面数据分片的思想，即**通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号**。 

但是，如果数据增多，原来的 10 个机器已经无法承受了，我们就需要扩容了，比如扩到 11 个机器，这时候麻烦就来了。因为，这里并不是简单地加个机器就可以了。 所有数据都要重新计算哈希值并搬移到正确的机器上去。

所以，我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。这时候，**一致性哈希算法**就要登场了 。

一致性哈希算法：

<img src="https://raw.githubusercontent.com/cszcsz/BlogCloudImg/master/surfaceimg/constant_hash.png" width=50% height=50%/>

假设哈希环上有100个节点，首先将分布式服务器映射到哈希环上(如对机器的ip地址进行哈希)。每当有数据经过哈希映射到环上的时候**顺时针**找到的第一个机器就是该数据被缓存的地方。这样，当有新机器加入或者有机器被删除时，**只要搬移相邻顺序上的一个机器中的数据**就可以了，其它地方完全不变。此外，**为了保证平衡性**（即缓存的数据平均的分散到各个机器上），可以在环上的为实际机器增加**虚拟节点**，每当有数据落到虚拟节点上就把它归属到相应的实际机器进行存储。